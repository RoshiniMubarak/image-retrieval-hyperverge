# -*- coding: utf-8 -*-
"""EVA_02.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14FSe8_kBCbWh7Txxp9jYVaAZmS4sJMIn
"""

pip install timm faiss-cpu torchvision matplotlib

import torch
import timm
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
import faiss
import numpy as np
import matplotlib.pyplot as plt

# Device setup
device = "cuda" if torch.cuda.is_available() else "cpu"

# Load EVA-02 model
model = timm.create_model('eva02_base_patch14_224.mim_in22k', pretrained=True)
model.to(device)
model.eval()

# Define preprocessing
preprocess = transforms.Compose([
    transforms.Resize(224),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize(
        mean=(0.5, 0.5, 0.5),
        std=(0.5, 0.5, 0.5)
    )
])
# Load CIFAR-100 dataset
def load_cifar100():
    dataset = datasets.CIFAR100(root="./data", train=True, download=True, transform=preprocess)
    dataloader = DataLoader(dataset, batch_size=128, shuffle=False, num_workers=2)
    return dataset, dataloader

dataset, dataloader = load_cifar100()
label_names = dataset.classes
labels = np.array(dataset.targets)

# Extract image embeddings using EVA-02
def get_embeddings(dataloader):
    all_features = []
    with torch.no_grad():
        for images, _ in dataloader:
            images = images.to(device)
            features = model.forward_features(images)
            features = features.mean(dim=1)  # Global average pooling
            features /= features.norm(dim=-1, keepdim=True)  # Normalize
            all_features.append(features.cpu().numpy())
    return np.vstack(all_features)

# Build FAISS index
def build_faiss_index(embeddings):
    index = faiss.IndexFlatL2(embeddings.shape[1])
    index.add(embeddings)
    return index

# Search using FAISS
def faiss_search(index, query_embedding, k=50):
    _, indices = index.search(query_embedding, k)
    return indices[0]

# Compute precision and false positive rate
def compute_metrics(retrieved_indices, query_labels, database_labels, k):
    total_true_positives = 0
    total_false_positives = 0
    total_queries = len(query_labels)

    for i in range(total_queries):
        retrieved = retrieved_indices[i]
        retrieved_labels = database_labels[retrieved]
        relevant_label = query_labels[i]

        tp = np.sum(retrieved_labels == relevant_label)
        fp = k - tp

        total_true_positives += tp
        total_false_positives += fp

    total_retrieved = total_queries * k
    precision = total_true_positives / total_retrieved if total_retrieved > 0 else 0
    fpr = total_false_positives / total_retrieved if total_retrieved > 0 else 0

    return precision, fpr

# Visualization of retrieval results
def show_results(query_img, faiss_idxs, original_dataset, query_label=None, faiss_precision=None, faiss_fpr=None):
    fig = plt.figure(figsize=(20, 12))

    # Display query image
    ax = plt.subplot(6, 10, 1)
    ax.imshow(query_img.permute(1, 2, 0))
    ax.set_title("Query\n(Class: Unknown)" if query_label is None else f"Query\n(Class: {label_names[query_label]})")
    ax.axis("off")

    # Display top 50 retrieved images
    for i, idx in enumerate(faiss_idxs[:50]):
        img, label = original_dataset[idx]
        ax = plt.subplot(6, 10, i + 2)
        ax.imshow(img.permute(1, 2, 0).clamp(0, 1))
        ax.set_title(f"FAISS {i+1}\n{label_names[label]}", fontsize=8)
        ax.axis("off")

    if faiss_precision is not None:
        fig.suptitle(f"FAISS Precision: {faiss_precision:.3f} | FPR: {faiss_fpr:.3f}", fontsize=16)

    plt.tight_layout()
    plt.show()

if __name__ == "__main__":
    print("Loading dataset and model...")
    dataset, dataloader = load_cifar100()
    label_names = dataset.classes
    labels = np.array(dataset.targets)

    embeddings = get_embeddings(dataloader)

    faiss_index = build_faiss_index(embeddings)
    print("FAISS Index built.")

# Use the same preprocessing for the original dataset
original_dataset = datasets.CIFAR100(root="./data", train=True, download=False, transform=preprocess)

query_indices = [300, 10, 3330, 1024, 5789]
ks = [10, 20, 30, 40, 50]

for i, query_idx in enumerate(query_indices):
    query_img, query_label = original_dataset[query_idx]
    query_img_tensor = query_img.unsqueeze(0).to(device)

    with torch.no_grad():
        query_embedding = model.forward_features(query_img_tensor)
        query_embedding = query_embedding.mean(dim=1)
        query_embedding /= query_embedding.norm(dim=-1, keepdim=True)
        query_embedding = query_embedding.cpu().numpy()

    faiss_results = faiss_search(faiss_index, query_embedding, k=50)

    print(f"\nQuery {i+1} (Index: {query_idx}, Label: {label_names[query_label]}):")
    for k in ks:
        precision_k, fpr_k = compute_metrics([faiss_results[:k]], [query_label], labels, k)
        print(f"Top-{k}: Precision = {precision_k:.3f}, FPR = {fpr_k:.3f}")

    show_results(query_img, faiss_results, original_dataset, query_label=query_label)