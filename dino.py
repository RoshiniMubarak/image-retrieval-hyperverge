# -*- coding: utf-8 -*-
"""DINO.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YXfo8YLuH3hMB5FegNsrbR3Xo78iBa1t
"""

pip install faiss-cpu

!pip install scikit-learn --upgrade

import torch
import timm
import faiss
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
import os

# Device setup
device = "cuda" if torch.cuda.is_available() else "cpu"

# Load pretrained DINO ViT model
model = timm.create_model("vit_small_patch16_224.dino", pretrained=True)
model.eval().to(device)

# Transform for CIFAR-100 + query image
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
])

# Load CIFAR-100 dataset
def load_cifar100():
    dataset = datasets.CIFAR100(root="./data", train=True, download=True, transform=transform)
    dataloader = DataLoader(dataset, batch_size=128, shuffle=False, num_workers=2)
    return dataset, dataloader

# Extract CLS token from DINO model
def get_dino_embeddings(dataloader):
    all_features = []
    with torch.no_grad():
        for images, _ in dataloader:
            images = images.to(device)
            features = model.forward_features(images)
            cls_features = features[:, 0]  # CLS token
            all_features.append(cls_features.cpu().numpy())
    return np.vstack(all_features)

# Build FAISS index with L2 distance (no normalization)
def build_faiss_index(embeddings):
    index = faiss.IndexFlatL2(embeddings.shape[1])  # L2 distance
    index.add(embeddings)
    return index

# FAISS search using L2 distance
def faiss_search(index, query_embedding, k=50):
    _, indices = index.search(query_embedding, k)
    return indices[0]

def compute_metrics(retrieved_indices, query_labels, database_labels, k=50):
    total_true_positives = 0
    total_false_positives = 0
    total_queries = len(query_labels)

    for i in range(total_queries):
        retrieved = retrieved_indices[i]
        retrieved_labels = database_labels[retrieved]
        relevant_label = query_labels[i]

        tp = np.sum(retrieved_labels == relevant_label)
        fp = k - tp  # since total retrieved = k

        total_true_positives += tp
        total_false_positives += fp

    total_retrieved = total_queries * k
    precision = total_true_positives / total_retrieved if total_retrieved > 0 else 0
    false_positive_rate = total_false_positives / total_retrieved if total_retrieved > 0 else 0

    return precision, false_positive_rate

# Show results using original images
def show_results(query_img, faiss_idxs, original_dataset, query_label=None, faiss_precision=None, faiss_fpr=None):
    fig = plt.figure(figsize=(20, 12))  # Adjusted the figure size for better display

    # Display query image
    ax = plt.subplot(6, 10, 1)  # Changed rows to 6, columns to 10 (total 60 subplots)
    ax.imshow(query_img.permute(1, 2, 0))
    ax.set_title("Query\n(Class: Unknown)" if query_label is None else f"Query\n(Class: {label_names[query_label]})")
    ax.axis("off")

    # Display top 50 retrieved images
    for i, idx in enumerate(faiss_idxs[:50]):
        img, label = original_dataset[idx]
        ax = plt.subplot(6, 10, i + 2)  # Adjusting grid to fit 51 images (6 rows x 10 columns)
        ax.imshow(img.permute(1, 2, 0).clamp(0, 1))  # Clamp values to valid range [0, 1] for imshow
        ax.set_title(f"FAISS {i+1}\n{label_names[label]}", fontsize=8)
        ax.axis("off")

    # Optionally, display precision and FPR in the title
    if faiss_precision is not None:
        fig.suptitle(f"FAISS Precision: {faiss_precision:.3f} | FPR: {faiss_fpr:.3f}", fontsize=16)

    plt.tight_layout()
    plt.show()

if __name__ == "__main__":
    print("Loading dataset and model...")
    dataset, dataloader = load_cifar100()
    label_names = dataset.classes
    labels = np.array(dataset.targets)

    embeddings = get_dino_embeddings(dataloader)
    embeddings = embeddings / np.linalg.norm(embeddings, axis=1, keepdims=True)

    faiss_index = build_faiss_index(embeddings)
    print("Index built.")

original_dataset = datasets.CIFAR100(root="./data", train=True, download=False, transform=transform)

query_indices = [300, 10, 3330, 1024, 5789]
ks = [10, 20, 30, 40, 50]

for i, query_idx in enumerate(query_indices):
    query_img, query_label = original_dataset[query_idx]
    query_img_tensor = query_img.unsqueeze(0).to(device)

    with torch.no_grad():
        query_embedding = model(query_img_tensor)
        query_embedding /= query_embedding.norm(dim=-1, keepdim=True)
        query_embedding = query_embedding.cpu().numpy()

    faiss_results = faiss_search(faiss_index, query_embedding, k=100)

    print(f"\nQuery {i+1} (Index: {query_idx}, Label: {label_names[query_label]}):")
    for k in ks:
        precision_k, fpr_k = compute_metrics([faiss_results[:k]], [query_label], labels,k)
        print(f"Top-{k}: Precision = {precision_k:.3f}, FPR = {fpr_k:.3f}")

    show_results(query_img, faiss_results, original_dataset, query_label=query_label)

from PIL import Image
 # Load original dataset without normalization for visualization
original_dataset = datasets.CIFAR100(root="./data", train=True, download=False, transform=transforms.ToTensor())
custom_image_paths = [
    "/content/istockphoto-94323862-612x612 (1).jpg",
    "/content/images (2).jpg",
    "/content/images (3).jpg"
]

all_query_embeddings = []
all_faiss_results = []

for i, path in enumerate(custom_image_paths):
    print(f"\nProcessing custom image: {path}")
    img = Image.open(path).convert("RGB")
    query_img = transform(img)
    input_tensor = query_img.unsqueeze(0).to(device)

    with torch.no_grad():
        query_feature = model.forward_features(input_tensor)[:, 0]
        query_embedding = query_feature.cpu().numpy()
        query_embedding = query_embedding / np.linalg.norm(query_embedding, axis=1, keepdims=True)

    faiss_results = faiss_search(faiss_index, query_embedding, k=10)

    all_query_embeddings.append(query_embedding[0])
    all_faiss_results.append(faiss_results)

    predicted_label = labels[faiss_results[0]]
    query_label = predicted_label

    precision, fpr = compute_metrics([faiss_results], [query_label], labels)

    show_results(query_img, faiss_results, original_dataset,
                     query_label=query_label, faiss_precision=precision, faiss_fpr=fpr)